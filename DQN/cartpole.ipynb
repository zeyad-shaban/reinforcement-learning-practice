{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "def get_action(net: torch.Tensor, state: torch.Tensor, epsilon: float) -> int:\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(0, 2)\n",
    "\n",
    "    return torch.argmax(net(state[None])).item()\n",
    "\n",
    "\n",
    "def add_transition(\n",
    "    replay_buffer: deque, elite_buffer: deque, transition: list, min_elite_val=None\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    transition is of shape (State, Action, Reward, NextState)\n",
    "    returns most minimum for future reference\n",
    "    \"\"\"\n",
    "    replay_buffer.append(transition)\n",
    "\n",
    "    if len(elite_buffer) < BATCH_SIZE / 2:\n",
    "        elite_buffer.append(transition)\n",
    "\n",
    "    else:\n",
    "        if min_elite_val is not None and transition[2] < min_elite_val:\n",
    "            return min_elite_val\n",
    "\n",
    "        min_elite = min(elite_buffer, key=lambda x: x[2])\n",
    "        if transition[2] > min_elite[2]:\n",
    "            elite_buffer.remove(min_elite)\n",
    "            elite_buffer.append(transition)\n",
    "\n",
    "            return min_elite[2]\n",
    "\n",
    "    return min_elite_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLAY_BUFFER_SIZE = 1000\n",
    "\n",
    "online_net = nn.Sequential(\n",
    "    nn.Linear(4, 128),\n",
    "    nn.ReLU(),\n",
    "    #\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    #\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    #\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    #\n",
    "    nn.Linear(16, 2),\n",
    ").to(device)\n",
    "\n",
    "target_net = deepcopy(online_net)\n",
    "\n",
    "\n",
    "replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "elite_buffer = deque(maxlen=BATCH_SIZE // 2)\n",
    "\n",
    "opt = optim.Adam(online_net.parameters(), lr=1e-2)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, epsilon: 0.4995, loss: 0.05066611245274544, max_R: 0, avg_R: 48.0\n",
      "episode: 1, epsilon: 0.4990005, loss: 0.7128541469573975, max_R: 11.0, avg_R: 11.0\n",
      "episode: 2, epsilon: 0.4985014995, loss: 0.4006396234035492, max_R: 77.0, avg_R: 44.0\n",
      "episode: 3, epsilon: 0.4980029980005, loss: 1.277982473373413, max_R: 77.0, avg_R: 33.666666666666664\n",
      "episode: 4, epsilon: 0.4975049950024995, loss: 0.7608539462089539, max_R: 229.0, avg_R: 82.5\n",
      "episode: 5, epsilon: 0.497007490007497, loss: 1.1547342538833618, max_R: 229.0, avg_R: 72.2\n",
      "episode: 6, epsilon: 0.4965104825174895, loss: 0.16062523424625397, max_R: 229.0, avg_R: 73.33333333333333\n",
      "episode: 7, epsilon: 0.49601397203497205, loss: 1.4712132215499878, max_R: 229.0, avg_R: 69.0\n",
      "episode: 8, epsilon: 0.4955179580629371, loss: 0.3880242705345154, max_R: 229.0, avg_R: 61.75\n",
      "episode: 9, epsilon: 0.4950224401048741, loss: 0.77504962682724, max_R: 229.0, avg_R: 56.77777777777778\n",
      "episode: 10, epsilon: 0.49452741766476926, loss: 0.19368968904018402, max_R: 229.0, avg_R: 63.5\n",
      "episode: 11, epsilon: 0.4940328902471045, loss: 1.0308431386947632, max_R: 229.0, avg_R: 62.63636363636363\n",
      "episode: 12, epsilon: 0.4935388573568574, loss: 1.0501620769500732, max_R: 229.0, avg_R: 66.33333333333333\n",
      "episode: 13, epsilon: 0.4930453184995005, loss: 0.49211472272872925, max_R: 229.0, avg_R: 69.3076923076923\n",
      "episode: 14, epsilon: 0.49255227318100103, loss: 0.4099298119544983, max_R: 229.0, avg_R: 76.0\n",
      "episode: 15, epsilon: 0.49205972090782, loss: 0.5904858112335205, max_R: 229.0, avg_R: 80.4\n",
      "episode: 16, epsilon: 0.4915676611869122, loss: 1.6139343976974487, max_R: 229.0, avg_R: 78.0625\n",
      "episode: 17, epsilon: 0.4910760935257253, loss: 0.07828376442193985, max_R: 229.0, avg_R: 75.94117647058823\n",
      "episode: 18, epsilon: 0.49058501743219957, loss: 0.4476677477359772, max_R: 229.0, avg_R: 79.0\n",
      "episode: 19, epsilon: 0.49009443241476736, loss: 0.22337691485881805, max_R: 229.0, avg_R: 79.6842105263158\n",
      "episode: 20, epsilon: 0.4896043379823526, loss: 0.3407558500766754, max_R: 229.0, avg_R: 78.0\n",
      "episode: 21, epsilon: 0.48911473364437025, loss: 0.6578056216239929, max_R: 229.0, avg_R: 83.47619047619048\n",
      "episode: 22, epsilon: 0.48862561891072587, loss: 0.285757839679718, max_R: 229.0, avg_R: 86.18181818181819\n",
      "episode: 23, epsilon: 0.48813699329181515, loss: 0.44737160205841064, max_R: 229.0, avg_R: 83.0\n",
      "episode: 24, epsilon: 0.48764885629852334, loss: 0.5211323499679565, max_R: 229.0, avg_R: 84.70833333333333\n",
      "episode: 25, epsilon: 0.4871612074422248, loss: 0.35740727186203003, max_R: 229.0, avg_R: 88.24\n",
      "episode: 26, epsilon: 0.48667404623478255, loss: 0.19943559169769287, max_R: 229.0, avg_R: 89.0\n",
      "episode: 27, epsilon: 0.4861873721885478, loss: 0.14435163140296936, max_R: 229.0, avg_R: 86.37037037037037\n",
      "episode: 28, epsilon: 0.48570118481635927, loss: 0.08924808353185654, max_R: 229.0, avg_R: 83.75\n",
      "episode: 29, epsilon: 0.48521548363154293, loss: 0.4437166154384613, max_R: 229.0, avg_R: 85.06896551724138\n",
      "episode: 30, epsilon: 0.48473026814791137, loss: 0.11724478006362915, max_R: 229.0, avg_R: 88.36666666666666\n",
      "episode: 31, epsilon: 0.48424553787976343, loss: 0.23519738018512726, max_R: 229.0, avg_R: 88.6774193548387\n",
      "episode: 32, epsilon: 0.48376129234188364, loss: 0.08889956027269363, max_R: 229.0, avg_R: 86.40625\n",
      "episode: 33, epsilon: 0.48327753104954174, loss: 0.0466291680932045, max_R: 229.0, avg_R: 86.0\n",
      "episode: 34, epsilon: 0.4827942535184922, loss: 0.05796714872121811, max_R: 229.0, avg_R: 85.82352941176471\n",
      "episode: 35, epsilon: 0.4823114592649737, loss: 0.5380373001098633, max_R: 229.0, avg_R: 88.51428571428572\n",
      "episode: 36, epsilon: 0.48182914780570874, loss: 0.15144631266593933, max_R: 229.0, avg_R: 91.08333333333333\n",
      "episode: 37, epsilon: 0.48134731865790303, loss: 0.041680656373500824, max_R: 229.0, avg_R: 93.48648648648648\n",
      "episode: 38, epsilon: 0.48086597133924514, loss: 0.029407011345028877, max_R: 229.0, avg_R: 94.57894736842105\n",
      "episode: 39, epsilon: 0.4803851053679059, loss: 0.022619588300585747, max_R: 229.0, avg_R: 97.58974358974359\n",
      "episode: 40, epsilon: 0.479904720262538, loss: 0.7046546339988708, max_R: 229.0, avg_R: 98.175\n",
      "episode: 41, epsilon: 0.47942481554227545, loss: 0.05215027183294296, max_R: 229.0, avg_R: 98.92682926829268\n",
      "episode: 42, epsilon: 0.4789453907267332, loss: 0.030797431245446205, max_R: 229.0, avg_R: 100.16666666666667\n",
      "episode: 43, epsilon: 0.47846644533600646, loss: 0.02837377041578293, max_R: 229.0, avg_R: 101.32558139534883\n",
      "episode: 44, epsilon: 0.47798797889067046, loss: 0.045906029641628265, max_R: 229.0, avg_R: 103.93181818181819\n",
      "episode: 45, epsilon: 0.4775099909117798, loss: 0.029412612318992615, max_R: 275.0, avg_R: 107.73333333333333\n",
      "episode: 46, epsilon: 0.47703248092086803, loss: 0.5126948952674866, max_R: 275.0, avg_R: 105.67391304347827\n",
      "episode: 47, epsilon: 0.4765554484399472, loss: 0.47997820377349854, max_R: 275.0, avg_R: 106.57446808510639\n",
      "episode: 48, epsilon: 0.47607889299150724, loss: 0.5463177561759949, max_R: 275.0, avg_R: 105.5\n",
      "episode: 49, epsilon: 0.47560281409851574, loss: 0.06080523878335953, max_R: 275.0, avg_R: 106.0204081632653\n",
      "episode: 50, epsilon: 0.4751272112844172, loss: 1.1582368612289429, max_R: 275.0, avg_R: 104.42\n",
      "episode: 51, epsilon: 0.4746520840731328, loss: 0.20681537687778473, max_R: 275.0, avg_R: 102.84313725490196\n",
      "episode: 52, epsilon: 0.47417743198905965, loss: 0.10012846440076828, max_R: 275.0, avg_R: 103.46153846153847\n",
      "episode: 53, epsilon: 0.4737032545570706, loss: 0.34028345346450806, max_R: 275.0, avg_R: 104.09433962264151\n",
      "episode: 54, epsilon: 0.4732295513025135, loss: 0.4815906584262848, max_R: 275.0, avg_R: 102.42592592592592\n",
      "episode: 55, epsilon: 0.47275632175121096, loss: 0.11493761837482452, max_R: 275.0, avg_R: 102.83636363636364\n",
      "episode: 56, epsilon: 0.47228356542945976, loss: 0.2772062420845032, max_R: 275.0, avg_R: 102.89285714285714\n",
      "episode: 57, epsilon: 0.4718112818640303, loss: 0.21701835095882416, max_R: 275.0, avg_R: 102.6140350877193\n",
      "episode: 58, epsilon: 0.4713394705821663, loss: 0.19375735521316528, max_R: 275.0, avg_R: 101.89655172413794\n",
      "episode: 59, epsilon: 0.47086813111158415, loss: 0.1216149628162384, max_R: 275.0, avg_R: 102.22033898305085\n",
      "episode: 60, epsilon: 0.4703972629804726, loss: 0.07876384258270264, max_R: 275.0, avg_R: 104.58333333333333\n",
      "episode: 61, epsilon: 0.4699268657174921, loss: 0.07620153576135635, max_R: 275.0, avg_R: 104.91803278688525\n",
      "episode: 62, epsilon: 0.4694569388517746, loss: 0.15785935521125793, max_R: 275.0, avg_R: 103.54838709677419\n",
      "episode: 63, epsilon: 0.46898748191292283, loss: 0.057723116129636765, max_R: 275.0, avg_R: 102.26984126984127\n",
      "episode: 64, epsilon: 0.4685184944310099, loss: 0.8755255937576294, max_R: 275.0, avg_R: 101.046875\n",
      "episode: 65, epsilon: 0.4680499759365789, loss: 0.10467798262834549, max_R: 275.0, avg_R: 100.2\n",
      "episode: 66, epsilon: 0.4675819259606423, loss: 0.05820693448185921, max_R: 275.0, avg_R: 101.74242424242425\n",
      "episode: 67, epsilon: 0.46711434403468166, loss: 0.39790335297584534, max_R: 275.0, avg_R: 100.65671641791045\n",
      "episode: 68, epsilon: 0.466647229690647, loss: 0.062139272689819336, max_R: 275.0, avg_R: 101.20588235294117\n",
      "episode: 69, epsilon: 0.46618058246095634, loss: 0.04861244559288025, max_R: 275.0, avg_R: 100.52173913043478\n",
      "episode: 70, epsilon: 0.4657144018784954, loss: 0.2551134526729584, max_R: 275.0, avg_R: 100.7\n",
      "episode: 71, epsilon: 0.4652486874766169, loss: 0.37995463609695435, max_R: 275.0, avg_R: 99.63380281690141\n",
      "episode: 72, epsilon: 0.4647834387891403, loss: 0.4844711422920227, max_R: 275.0, avg_R: 99.02777777777777\n",
      "episode: 73, epsilon: 0.46431865535035116, loss: 0.05902962014079094, max_R: 275.0, avg_R: 97.86301369863014\n",
      "episode: 74, epsilon: 0.4638543366950008, loss: 0.6329489946365356, max_R: 275.0, avg_R: 98.52702702702703\n",
      "episode: 75, epsilon: 0.4633904823583058, loss: 0.15742266178131104, max_R: 275.0, avg_R: 98.08\n",
      "episode: 76, epsilon: 0.4629270918759475, loss: 0.3034854233264923, max_R: 275.0, avg_R: 98.4342105263158\n",
      "episode: 77, epsilon: 0.46246416478407154, loss: 0.6933717131614685, max_R: 275.0, avg_R: 99.42857142857143\n",
      "episode: 78, epsilon: 0.46200170061928747, loss: 0.6486058831214905, max_R: 275.0, avg_R: 99.58974358974359\n",
      "episode: 79, epsilon: 0.4615396989186682, loss: 0.05812038853764534, max_R: 275.0, avg_R: 99.46835443037975\n",
      "episode: 80, epsilon: 0.46107815921974954, loss: 0.143888920545578, max_R: 275.0, avg_R: 99.5\n",
      "episode: 81, epsilon: 0.4606170810605298, loss: 0.0468011312186718, max_R: 275.0, avg_R: 98.91358024691358\n",
      "episode: 82, epsilon: 0.46015646397946924, loss: 0.32345452904701233, max_R: 275.0, avg_R: 97.91463414634147\n",
      "episode: 83, epsilon: 0.4596963075154898, loss: 0.05385850742459297, max_R: 275.0, avg_R: 98.7710843373494\n",
      "episode: 84, epsilon: 0.4592366112079743, loss: 0.03220197558403015, max_R: 275.0, avg_R: 100.21428571428571\n",
      "episode: 85, epsilon: 0.4587773745967664, loss: 0.025162504985928535, max_R: 275.0, avg_R: 99.29411764705883\n",
      "episode: 86, epsilon: 0.4583185972221696, loss: 0.22897033393383026, max_R: 275.0, avg_R: 98.32558139534883\n",
      "episode: 87, epsilon: 0.45786027862494744, loss: 0.024193234741687775, max_R: 275.0, avg_R: 98.55172413793103\n",
      "episode: 88, epsilon: 0.4574024183463225, loss: 0.03334513679146767, max_R: 275.0, avg_R: 99.2159090909091\n",
      "episode: 89, epsilon: 0.4569450159279762, loss: 0.1769501119852066, max_R: 275.0, avg_R: 99.04494382022472\n",
      "episode: 90, epsilon: 0.45648807091204824, loss: 0.04330063611268997, max_R: 275.0, avg_R: 99.2\n",
      "episode: 91, epsilon: 0.4560315828411362, loss: 0.16781550645828247, max_R: 275.0, avg_R: 99.65934065934066\n",
      "episode: 92, epsilon: 0.4555755512582951, loss: 0.05577515438199043, max_R: 275.0, avg_R: 99.57608695652173\n",
      "episode: 93, epsilon: 0.4551199757070368, loss: 0.7808235883712769, max_R: 275.0, avg_R: 99.66666666666667\n",
      "episode: 94, epsilon: 0.45466485573132975, loss: 0.07131068408489227, max_R: 275.0, avg_R: 99.27659574468085\n",
      "episode: 95, epsilon: 0.45421019087559844, loss: 0.07653006911277771, max_R: 275.0, avg_R: 98.91578947368421\n",
      "episode: 96, epsilon: 0.45375598068472284, loss: 0.32795774936676025, max_R: 275.0, avg_R: 98.15625\n",
      "episode: 97, epsilon: 0.45330222470403814, loss: 0.05511431396007538, max_R: 275.0, avg_R: 98.3298969072165\n",
      "episode: 98, epsilon: 0.4528489224793341, loss: 0.08502641320228577, max_R: 275.0, avg_R: 97.41836734693878\n",
      "episode: 99, epsilon: 0.4523960735568548, loss: 0.0615476593375206, max_R: 275.0, avg_R: 96.73737373737374\n",
      "episode: 100, epsilon: 0.45194367748329795, loss: 0.2536535859107971, max_R: 0, avg_R: 96.56\n",
      "episode: 101, epsilon: 0.45149173380581464, loss: 0.9486253261566162, max_R: 13.0, avg_R: 13.0\n",
      "episode: 102, epsilon: 0.4510402420720088, loss: 0.2928134799003601, max_R: 73.0, avg_R: 43.0\n",
      "episode: 103, epsilon: 0.45058920182993684, loss: 0.670295774936676, max_R: 73.0, avg_R: 48.333333333333336\n",
      "episode: 104, epsilon: 0.4501386126281069, loss: 0.529190182685852, max_R: 73.0, avg_R: 41.25\n",
      "episode: 105, epsilon: 0.4496884740154788, loss: 0.782974362373352, max_R: 73.0, avg_R: 36.4\n",
      "episode: 106, epsilon: 0.4492387855414633, loss: 0.22065414488315582, max_R: 73.0, avg_R: 36.166666666666664\n",
      "episode: 107, epsilon: 0.4487895467559218, loss: 0.3516669273376465, max_R: 122.0, avg_R: 48.42857142857143\n",
      "episode: 108, epsilon: 0.4483407572091659, loss: 1.2011570930480957, max_R: 234.0, avg_R: 71.625\n",
      "episode: 109, epsilon: 0.4478924164519567, loss: 0.3359707295894623, max_R: 234.0, avg_R: 71.44444444444444\n",
      "episode: 110, epsilon: 0.4474445240355048, loss: 0.8772827386856079, max_R: 234.0, avg_R: 78.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     68\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 69\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m target_net_update_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     72\u001b[0m     R_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.venv/pytorch_env/lib/python3.12/site-packages/torch/optim/optimizer.py:467\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprofile_hook_step\u001b[39m(func: Callable[_P, R]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[_P, R]:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m R:\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPS_DECAY_RATE = 0.001\n",
    "MIN_EPS = 0.1\n",
    "GAMMA = 0.99\n",
    "epsilon = 0.5\n",
    "episodes = 1000\n",
    "target_net_update_freq = 100\n",
    "\n",
    "avg_R_div = 0\n",
    "R_sum = 0\n",
    "max_R = 0\n",
    "min_elite_val = None\n",
    "\n",
    "for episode in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    epsilon = max(epsilon - EPS_DECAY_RATE * epsilon, MIN_EPS)\n",
    "\n",
    "    R = 0\n",
    "\n",
    "    while True:\n",
    "        state = torch.tensor(obs, device=device)\n",
    "        action = get_action(online_net, state, epsilon)\n",
    "\n",
    "        next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        R += reward\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "\n",
    "        next_state = torch.tensor(next_obs, device=device)\n",
    "        transition = (state, action, reward, next_state, float(done))\n",
    "\n",
    "        min_elite_val = add_transition(\n",
    "            replay_buffer, elite_buffer, transition, min_elite_val\n",
    "        )\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    max_R = max(max_R, R)\n",
    "    avg_R_div += 1\n",
    "    R_sum += R\n",
    "    avg_R = (R_sum) / (avg_R_div)\n",
    "\n",
    "    sample = random.sample(\n",
    "        replay_buffer, k=min(len(replay_buffer), BATCH_SIZE // 2)\n",
    "    ) + list(elite_buffer)\n",
    "\n",
    "    states, actions, rewards, next_states, dones = zip(*sample)\n",
    "\n",
    "    states_t = torch.stack(states)  # Shape(Bx4)\n",
    "    actions_t = torch.tensor(actions, device=device, dtype=torch.int64).view(\n",
    "        -1, 1\n",
    "    )  # Shape(Bx1)\n",
    "    rewards_t = torch.tensor(rewards, device=device, dtype=torch.float32).view(\n",
    "        -1, 1\n",
    "    )  # Shape(Bx1)\n",
    "    next_states_t = torch.stack(next_states)  # Shape(Bx4)\n",
    "    dones_t = torch.tensor(dones, device=device, dtype=torch.float32).view(\n",
    "        -1, 1\n",
    "    )  # Shape(Bx1)\n",
    "\n",
    "    q_pred = online_net(states_t)  # Shape(Bx2)\n",
    "    q_pred = q_pred.gather(1, actions_t)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_next_state = target_net(next_states_t)  # Shape(Bx2)\n",
    "        q_next_max = q_next_state.max(dim=1)[0].view(-1, 1)\n",
    "        q_target = rewards_t + (1 - dones_t) * GAMMA * q_next_max  # Shape(B)\n",
    "\n",
    "    loss = criterion(q_pred, q_target)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if episode % target_net_update_freq == 0:\n",
    "        R_sum = 0\n",
    "        avg_R_div = 0\n",
    "        max_R = 0\n",
    "        target_net = deepcopy(online_net)\n",
    "\n",
    "    print(\n",
    "        f\"episode: {episode}, epsilon: {epsilon}, loss: {loss}, max_R: {max_R}, avg_R: {avg_R}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(online_net.state_dict(), './cartpole_dqn.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
